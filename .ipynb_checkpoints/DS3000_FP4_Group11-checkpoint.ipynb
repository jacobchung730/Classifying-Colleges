{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> DS 3000 - Fall 2021</h2> </center>\n",
    "<center> <h3> DS Report </h3> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3>Which Type of College is Right for You: Public, Private, or For-Profit?</h3> </center>\n",
    "<center><h4>Sophia Akhter, Cheryl Leigh, Jacob Chung</h4></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executive Summary:\n",
    "\n",
    "Our project is designed to help people apply to college, especially the underprivileged, by allowing them to fill out their ideal university criteria details and helping them figure out whether to look into public, private, or for-profit universities as they begin their college application process. Many students do not have access to good college resources such as counselors or might be the first in their families to navigate the applications, so figuring out the best type of universities to fit them is an important step.\n",
    "\n",
    "We obtained our dataset from Kaggle. After performing various data wrangling and manipulation, we found it was most efficient to one-hot encode our categorical variables and now use quantitative variables such as as tuition, enrollment, and location. Given some of these feature variables as input, our algorithm will be able to predict whether a school with those characteristics is more likely to be public, private, or for profit.\n",
    "\n",
    "We started off by using k-Nearest Neighbors, Guassian Naive Bayes, and Decision Tree. By using recusive feature elimination and hyper parameter tuning, we were able to improve the accuracy of our results. We discovered that the two most efficient algorithms to use were k-Nearest Neighbors and Decision Tree, with Decision Tree performing slightly more optimally. \n",
    "\n",
    "Upon concluding our project, we were able to determine that the three most important features in classifying a school as public, private, or for-profit are in_state_tuition, out_of_state_total, and total_enrollment. In the future, we feel that we could use more feature variables, add more data points, and also train our model with other algorithms such as Support Vector Machine. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. <a href='#1'>INTRODUCTION</a>\n",
    "2. <a href='#2'>METHOD</a>\n",
    "3. <a href='#3'>RESULTS</a>\n",
    "4. <a href='#4'>DISCUSSION</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Problem Statement</h4>\n",
    "\n",
    "Our project focuses on helping students apply to college by narrowing down their choices. Nowadays it is almost essential to obtain a college degree in order to gain an advantage in the workforce and have a step up in life. A college degree is seen in our society almost as a commodity because it carries much more social value than just pure knowledge and education. For our project, we will try to classify colleges into either public, private, or for-profit universities based on criteria that a prospective student might be looking for. For a student who is beginning their college process and has an idea of the enrollment size they would like, the ideal tuition cost, or location, our project could be of benefit to them. Our algorithm will point them toward the best type of institution options for them by predicting whether their inputs fall into the public, private, or for-profit categories.\n",
    "\n",
    "<h4>Significance of the Problem</h4>\n",
    "\n",
    "We believe that it is important to tackle this problem because it is relevant to us as students along with the\n",
    "whole country as a system. Some people in our world unfortunately do not have access to as many resources to be as\n",
    "knowledgeable about the college process as others. For example, first generation applicants or those who do not have college counselors are people who might need guidance about what types of schools to look for, given their backgrounds and preferences. Ideally, our program would be a resource for anyone with internet access to learn more about the best college type for them.\n",
    "\n",
    "<h4>Questions</h4>\n",
    "\n",
    "Do schools have enough common charactersitics among each other to train an ML algorithm? On the other hand, is each college too unique from each other or to be able to do accurately do this?\n",
    "\n",
    "How do the k-nearest neighbors, gasussian naive bayes, and decision tree algorithms compare in correctly predicting a college type based on the given features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data Acquisition\n",
    "\n",
    "We obtained our data from kaggle.com (https://www.kaggle.com/jessemostipak/college-tuition-diversity-and-pay?select=diversity_school.csv). There were multiple csv files where we ultimately had to do some data wranging and merging between multiple csv files.\n",
    "\n",
    "After doing the required data wrangling and transformation (which we talk about in the next section), we finally arrived at our feature and outcome variables. This dataset initially included all quantitative variables except degree_length and state. We then one-hot encoded them to get them to become quantative variables (we also talk about this in a later section). Now all of our variables are quantitative.\n",
    "\n",
    "* type: a college can either be private, public, or for profit \n",
    "* room_and_board: the price to live at the college \n",
    "* in_state_tuition: if a person lives in the state of the college, they will pay this price\n",
    "* in_state_total: in state tuition + room and baord\n",
    "* out_of_state_tuition: if a person does not live in the state of the college, they will pay this price\n",
    "* out_of_state_total: out of state tuition + room and board\n",
    "* total_enrollment: how many students attend this college\n",
    "* degree_length_2 Year: whether the degree length is 2 years\n",
    "* degree_length_4 Year: whether the degree length is 4 years\n",
    "* state: where the college is located, we have made this to be 50 columns, each represnting a US state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data Analysis\n",
    "\n",
    "Our target varible will be the type of college, and all other variables will be feature variables. Therefore, we will be predicting whether a college is private, public, or for profit given the feature variables. \n",
    "\n",
    "We think that in state tuition, out of state tuition, total enrollment, and whether the degree length is 2 vs 4 years will all play important factors. For example, we know that public schools tend to have a lower in state tuition than a private school. We also think that total enrollment may play a factor because public schools tend to be really large while some private schools are very small.\n",
    "\n",
    "This is a supervised ML classification problem beacause we are trying to learn by example. We will be using ML algorithms that will take in data and answers and return some rules. Under the hood, these rules will now be used to predict and classify a type of college.  \n",
    "\n",
    "The three ML algorithms we will be using are as follows: \n",
    "\n",
    "* k-Nearest Neighbors: This algorithm first finds the k most similar instances based on distance between this point and other points. Then it gets the labels of these instances and a majority vote is taken to determine the prediction. The pro is that this has reasonable performance without a lot of adjustments, but the con is that it can be pretty slow. We chose this because from what we have seen with past datasets, this algorithm has high performance. \n",
    "\n",
    "\n",
    "* Gaussian Naive Bayes: This algorithm is a probabilistic algorithm that makes the assumption that all features are equally important. The pro is that this works well with high dimensional data, but the con is that the assumption that features are conditionally independent is naive. We think this will be a good baseline to compare to our other algorithms to see if features may relate to each other. \n",
    "\n",
    "\n",
    "* Decision Tree: This algorithm uses a hierarchy of if/else questions which can quickly lead to a decision. The pro is that no feature normalization or scaling is typically needed, but the con is that we usually need multiples of trees for better generalization performance. We chose this because it breaks down complex data into more manageable parts and is easy to visualize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import plotly.express as px\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>type</th>\n",
       "      <th>degree_length</th>\n",
       "      <th>room_and_board</th>\n",
       "      <th>in_state_tuition</th>\n",
       "      <th>in_state_total</th>\n",
       "      <th>out_of_state_tuition</th>\n",
       "      <th>out_of_state_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <th>Texas</th>\n",
       "      <td>TX</td>\n",
       "      <td>Private</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abraham Baldwin Agricultural College</th>\n",
       "      <th>Georgia</th>\n",
       "      <td>GA</td>\n",
       "      <td>Public</td>\n",
       "      <td>2 Year</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>4128</td>\n",
       "      <td>12602</td>\n",
       "      <td>12550</td>\n",
       "      <td>21024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Academy of Art University</th>\n",
       "      <th>California</th>\n",
       "      <td>CA</td>\n",
       "      <td>For Profit</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>16648.0</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adams State University</th>\n",
       "      <th>Colorado</th>\n",
       "      <td>CO</td>\n",
       "      <td>Public</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>8782.0</td>\n",
       "      <td>9440</td>\n",
       "      <td>18222</td>\n",
       "      <td>20456</td>\n",
       "      <td>29238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <th>New York</th>\n",
       "      <td>NY</td>\n",
       "      <td>Private</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>16030.0</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                state_code        type  \\\n",
       "name                                 state                               \n",
       "Abilene Christian University         Texas              TX     Private   \n",
       "Abraham Baldwin Agricultural College Georgia            GA      Public   \n",
       "Academy of Art University            California         CA  For Profit   \n",
       "Adams State University               Colorado           CO      Public   \n",
       "Adelphi University                   New York           NY     Private   \n",
       "\n",
       "                                                degree_length  room_and_board  \\\n",
       "name                                 state                                      \n",
       "Abilene Christian University         Texas             4 Year         10350.0   \n",
       "Abraham Baldwin Agricultural College Georgia           2 Year          8474.0   \n",
       "Academy of Art University            California        4 Year         16648.0   \n",
       "Adams State University               Colorado          4 Year          8782.0   \n",
       "Adelphi University                   New York          4 Year         16030.0   \n",
       "\n",
       "                                                 in_state_tuition  \\\n",
       "name                                 state                          \n",
       "Abilene Christian University         Texas                  34850   \n",
       "Abraham Baldwin Agricultural College Georgia                 4128   \n",
       "Academy of Art University            California             27810   \n",
       "Adams State University               Colorado                9440   \n",
       "Adelphi University                   New York               38660   \n",
       "\n",
       "                                                 in_state_total  \\\n",
       "name                                 state                        \n",
       "Abilene Christian University         Texas                45200   \n",
       "Abraham Baldwin Agricultural College Georgia              12602   \n",
       "Academy of Art University            California           44458   \n",
       "Adams State University               Colorado             18222   \n",
       "Adelphi University                   New York             54690   \n",
       "\n",
       "                                                 out_of_state_tuition  \\\n",
       "name                                 state                              \n",
       "Abilene Christian University         Texas                      34850   \n",
       "Abraham Baldwin Agricultural College Georgia                    12550   \n",
       "Academy of Art University            California                 27810   \n",
       "Adams State University               Colorado                   20456   \n",
       "Adelphi University                   New York                   38660   \n",
       "\n",
       "                                                 out_of_state_total  \n",
       "name                                 state                           \n",
       "Abilene Christian University         Texas                    45200  \n",
       "Abraham Baldwin Agricultural College Georgia                  21024  \n",
       "Academy of Art University            California               44458  \n",
       "Adams State University               Colorado                 29238  \n",
       "Adelphi University                   New York                 54690  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after reading the csv file, we drop all the rows with NA values \n",
    "# these NA values appeared in room_and_board\n",
    "\n",
    "# corresponds to tuition_cost.csv\n",
    "url = \"https://raw.githubusercontent.com/jacobchung730/ds3000FinalProject/master/ds3000_data/tuition_cost.csv?token=AT6KX2ONPPIKKK723FVLGXLBXT6IY\"\n",
    "one = pd.read_csv(url, index_col=[\"name\", \"state\"])\n",
    "one = one.dropna()\n",
    "one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_enrollment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>University of Phoenix-Arizona</th>\n",
       "      <th>Arizona</th>\n",
       "      <td>195059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ivy Tech Community College-Central Indiana</th>\n",
       "      <th>Indiana</th>\n",
       "      <td>91179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liberty University</th>\n",
       "      <th>Virginia</th>\n",
       "      <td>81459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lone Star College system</th>\n",
       "      <th>Texas</th>\n",
       "      <td>69395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami Dade College</th>\n",
       "      <th>Florida</th>\n",
       "      <td>66046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     total_enrollment\n",
       "name                                       state                     \n",
       "University of Phoenix-Arizona              Arizona             195059\n",
       "Ivy Tech Community College-Central Indiana Indiana              91179\n",
       "Liberty University                         Virginia             81459\n",
       "Lone Star College system                   Texas                69395\n",
       "Miami Dade College                         Florida              66046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after reading the csv file, we drop unneeded columns: category and enrollemnt\n",
    "# these two columns that we dropped had the enrollment PER category\n",
    "# ultimately, we just need the TOTAL enrollment per college\n",
    "# we also dropped any duplciate rows\n",
    "\n",
    "# corresponds to diversity_school.csv\n",
    "url = \"https://raw.githubusercontent.com/jacobchung730/ds3000FinalProject/master/ds3000_data/diversity_school.csv?token=AT6KX2KBJ7UHUZRGDAOWBMDBXT6CQ\"\n",
    "two = pd.read_csv(url, index_col=[\"name\", \"state\"])\n",
    "two = two.drop(\"category\",1)\n",
    "two = two.drop(\"enrollment\",1)\n",
    "two = two.drop_duplicates()\n",
    "two.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>degree_length</th>\n",
       "      <th>room_and_board</th>\n",
       "      <th>in_state_tuition</th>\n",
       "      <th>in_state_total</th>\n",
       "      <th>out_of_state_tuition</th>\n",
       "      <th>out_of_state_total</th>\n",
       "      <th>total_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>Private</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "      <td>4427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>Public</td>\n",
       "      <td>2 Year</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>4128</td>\n",
       "      <td>12602</td>\n",
       "      <td>12550</td>\n",
       "      <td>21024</td>\n",
       "      <td>3458.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>For Profit</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>16648.0</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "      <td>15212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>Public</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>8782.0</td>\n",
       "      <td>9440</td>\n",
       "      <td>18222</td>\n",
       "      <td>20456</td>\n",
       "      <td>29238</td>\n",
       "      <td>3154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York</td>\n",
       "      <td>Private</td>\n",
       "      <td>4 Year</td>\n",
       "      <td>16030.0</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "      <td>7610.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state        type degree_length  room_and_board  in_state_tuition  \\\n",
       "0       Texas     Private        4 Year         10350.0             34850   \n",
       "1     Georgia      Public        2 Year          8474.0              4128   \n",
       "2  California  For Profit        4 Year         16648.0             27810   \n",
       "3    Colorado      Public        4 Year          8782.0              9440   \n",
       "4    New York     Private        4 Year         16030.0             38660   \n",
       "\n",
       "   in_state_total  out_of_state_tuition  out_of_state_total  total_enrollment  \n",
       "0           45200                 34850               45200            4427.0  \n",
       "1           12602                 12550               21024            3458.0  \n",
       "2           44458                 27810               44458           15212.0  \n",
       "3           18222                 20456               29238            3154.0  \n",
       "4           54690                 38660               54690            7610.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we merge the two dataframes so that our new dataframe can have enrollment per college\n",
    "# we reset the indices to natural numbers \n",
    "# we merged over the name and state \n",
    "# we drop name and state code\n",
    "# we already had the state name, so having the state code would be redundant\n",
    "final = pd.merge(one, two, on=[\"name\", \"state\"], how=\"left\")\n",
    "final = final.reset_index()\n",
    "final = final.drop(\"name\",1)\n",
    "final = final.drop(\"state_code\",1)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to one-hot encode the degree_length column: 2 Year and 4 Year\n",
    "# we wanted to do this because we needed to change from categorical to quantitative variables\n",
    "# we went from having 1 degree_length column to now having 2 columns\n",
    "length = final[\"degree_length\"].values.reshape(-1,1)\n",
    "encoder = OneHotEncoder(sparse = False)\n",
    "\n",
    "encoded_df = encoder.fit_transform(length)\n",
    "\n",
    "features_df = pd.DataFrame(encoded_df, columns = encoder.get_feature_names([\"degree_length\"]))\n",
    "\n",
    "df_merged = final.merge(features_df, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to one-hot encode the state column: 50 states in the USA\n",
    "# we wanted to do this because we needed to change from categorical to quantitative variables\n",
    "# we went from having 1 state column to now having 50 columns, one representing each state\n",
    "location = final[\"state\"].values.reshape(-1,1)\n",
    "\n",
    "encoder1 = OneHotEncoder(sparse = False)\n",
    "\n",
    "encoded_df1 = encoder1.fit_transform(location)\n",
    "\n",
    "features_df1 = pd.DataFrame(encoded_df1, columns = encoder1.get_feature_names([\"state\"]))\n",
    "\n",
    "df_merged1 = df_merged.merge(features_df1, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>room_and_board</th>\n",
       "      <th>in_state_tuition</th>\n",
       "      <th>in_state_total</th>\n",
       "      <th>out_of_state_tuition</th>\n",
       "      <th>out_of_state_total</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>degree_length_2 Year</th>\n",
       "      <th>degree_length_4 Year</th>\n",
       "      <th>state_Alabama</th>\n",
       "      <th>...</th>\n",
       "      <th>state_South Dakota</th>\n",
       "      <th>state_Tennessee</th>\n",
       "      <th>state_Texas</th>\n",
       "      <th>state_Utah</th>\n",
       "      <th>state_Vermont</th>\n",
       "      <th>state_Virginia</th>\n",
       "      <th>state_Washington</th>\n",
       "      <th>state_West Virginia</th>\n",
       "      <th>state_Wisconsin</th>\n",
       "      <th>state_Wyoming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>10350.0</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "      <td>34850</td>\n",
       "      <td>45200</td>\n",
       "      <td>4427.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Public</td>\n",
       "      <td>8474.0</td>\n",
       "      <td>4128</td>\n",
       "      <td>12602</td>\n",
       "      <td>12550</td>\n",
       "      <td>21024</td>\n",
       "      <td>3458.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For Profit</td>\n",
       "      <td>16648.0</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "      <td>27810</td>\n",
       "      <td>44458</td>\n",
       "      <td>15212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Public</td>\n",
       "      <td>8782.0</td>\n",
       "      <td>9440</td>\n",
       "      <td>18222</td>\n",
       "      <td>20456</td>\n",
       "      <td>29238</td>\n",
       "      <td>3154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>16030.0</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "      <td>38660</td>\n",
       "      <td>54690</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         type  room_and_board  in_state_tuition  in_state_total  \\\n",
       "0     Private         10350.0             34850           45200   \n",
       "1      Public          8474.0              4128           12602   \n",
       "2  For Profit         16648.0             27810           44458   \n",
       "3      Public          8782.0              9440           18222   \n",
       "4     Private         16030.0             38660           54690   \n",
       "\n",
       "   out_of_state_tuition  out_of_state_total  total_enrollment  \\\n",
       "0                 34850               45200            4427.0   \n",
       "1                 12550               21024            3458.0   \n",
       "2                 27810               44458           15212.0   \n",
       "3                 20456               29238            3154.0   \n",
       "4                 38660               54690            7610.0   \n",
       "\n",
       "   degree_length_2 Year  degree_length_4 Year  state_Alabama  ...  \\\n",
       "0                   0.0                   1.0            0.0  ...   \n",
       "1                   1.0                   0.0            0.0  ...   \n",
       "2                   0.0                   1.0            0.0  ...   \n",
       "3                   0.0                   1.0            0.0  ...   \n",
       "4                   0.0                   1.0            0.0  ...   \n",
       "\n",
       "   state_South Dakota  state_Tennessee  state_Texas  state_Utah  \\\n",
       "0                 0.0              0.0          1.0         0.0   \n",
       "1                 0.0              0.0          0.0         0.0   \n",
       "2                 0.0              0.0          0.0         0.0   \n",
       "3                 0.0              0.0          0.0         0.0   \n",
       "4                 0.0              0.0          0.0         0.0   \n",
       "\n",
       "   state_Vermont  state_Virginia  state_Washington  state_West Virginia  \\\n",
       "0            0.0             0.0               0.0                  0.0   \n",
       "1            0.0             0.0               0.0                  0.0   \n",
       "2            0.0             0.0               0.0                  0.0   \n",
       "3            0.0             0.0               0.0                  0.0   \n",
       "4            0.0             0.0               0.0                  0.0   \n",
       "\n",
       "   state_Wisconsin  state_Wyoming  \n",
       "0              0.0            0.0  \n",
       "1              0.0            0.0  \n",
       "2              0.0            0.0  \n",
       "3              0.0            0.0  \n",
       "4              0.0            0.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after one hot encoding, we drop the original degree_length and state columsn because we have our new columns now\n",
    "df_merged1 = df_merged1.drop(\"degree_length\", 1)\n",
    "df_merged1 = df_merged1.drop(\"state\", 1)\n",
    "\n",
    "# drop all NA values because some schools did not have an enrollment count in our dataset\n",
    "# we also reset the index because we had removed some rows so some indicies were missing previously\n",
    "df_merged1 = df_merged1.dropna()\n",
    "df_merged1 = df_merged1.drop(\"state_nan\", 1)\n",
    "df_merged1 = df_merged1.reset_index()\n",
    "df_merged1 = df_merged1.drop(\"index\",1)\n",
    "df_merged1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>For Profit</th>\n",
       "      <td>9</td>\n",
       "      <td>10764.111111</td>\n",
       "      <td>19904.722841</td>\n",
       "      <td>6634.907614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Private</th>\n",
       "      <td>620</td>\n",
       "      <td>4079.814516</td>\n",
       "      <td>6082.055651</td>\n",
       "      <td>244.261233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public</th>\n",
       "      <td>469</td>\n",
       "      <td>10602.908316</td>\n",
       "      <td>10449.964650</td>\n",
       "      <td>482.534534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count          mean           std          sem\n",
       "type                                                      \n",
       "For Profit      9  10764.111111  19904.722841  6634.907614\n",
       "Private       620   4079.814516   6082.055651   244.261233\n",
       "Public        469  10602.908316  10449.964650   482.534534"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptives = df_merged.groupby([\"type\"]).agg([\"count\", \"mean\", \"std\", \"sem\"])[\"total_enrollment\"]\n",
    "descriptives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives = descriptives.reset_index()\n",
    "\n",
    "graph = px.bar(descriptives, x = \"type\", y = \"mean\", color = \"type\",\n",
    "               error_x = \"sem\", error_y = \"sem\", labels = {\"mean\": \"Average Enrollment\"},\n",
    "               template='ggplot2', color_discrete_sequence=[\"darkslateblue\", \"indianred\", \"darkseagreen\"], \n",
    "               width = 550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1 Bar Chart\n",
    "<img src=\"https://i.ibb.co/WHjL8Tq/Screen-Shot-2021-12-10-at-3-57-07-PM.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation for bar chart**: On the x axis we have the type of school: for profit, private, and public. We are comparing this to the y axis which is average enrollment. As the visualization shows, public and for profit schools typically have higher enrollment counts while a private school on avergae has less students. Enrollment count could be an important feature variable in classifying type of school. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = px.box(df_merged, x= \"type\", y= \"in_state_total\", color = \"type\",\n",
    "               template='ggplot2',\n",
    "               color_discrete_sequence=[\"indianred\", \"darkseagreen\", \"darkslateblue\"], \n",
    "               width = 550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2 Box Plot\n",
    "<img src=\"https://i.ibb.co/bJRKCKY/Screen-Shot-2021-12-09-at-2-01-08-PM.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation for box plot**: We can see that out of the three types of schools, public has the lowest in state tuition. The max for in-state tuition is even less than the median tution for private and for-profit schools. We can also see that the max private school tuition is over 70k, which is insanely high compared to public and for-profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = px.violin(df_merged, x= \"type\", y= \"out_of_state_total\", color = \"type\", \n",
    "                  points=\"all\", template='ggplot2',\n",
    "                  color_discrete_sequence=[\"indianred\", \"darkseagreen\", \"darkslateblue\"], \n",
    "                  width = 550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 3 Violin Plot\n",
    "<img src=\"https://i.ibb.co/bzVCtm6/Screen-Shot-2021-12-09-at-2-01-03-PM.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation for violin plot**: When looking at this violin plot, we can also see the densities for all of our data points. We can see that the out of state tuiton for public schools are densely populated around 10k to 30k while private schools is pretty evenly populated throughout 20k to 70k. When looking at out of state vs in state tution, it is looking like in state tution will probably be a more important feature variable. There are also a lot of private and public data points. However, there are not many for profit data points so this might be a flaw in our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'k-Nearest Neighbor': KNeighborsClassifier(), \n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the target and feature variables \n",
    "features = df_merged1.drop(\"type\", axis = 1)\n",
    "target = df_merged1[\"type\"]\n",
    "\n",
    "# splits the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features after RFE:\n",
      "\t in_state_tuition\n",
      "\t out_of_state_total\n",
      "\t total_enrollment\n"
     ]
    }
   ],
   "source": [
    "# we are using recursive feature elimination to select the three most important features for our classification\n",
    "select = RFE(DecisionTreeClassifier(random_state = 3000), n_features_to_select = 3)\n",
    "\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "    \n",
    "model = DecisionTreeClassifier().fit(X=X_train, y=y_train)\n",
    "    \n",
    "mapping = list(zip(features.columns, select.get_support()))\n",
    "    \n",
    "print(\"Selected features after RFE:\")\n",
    "for item in mapping:\n",
    "    if item[1] == True:\n",
    "        print(\"\\t\", item[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST RESULTS WITH ALL FEATURES:\n",
      "\t k-Nearest Neighbor: \n",
      "\t\tClassification accurary on the test data: 96.36%\n",
      "\n",
      "\t Gaussian Naive Bayes: \n",
      "\t\tClassification accurary on the test data: 89.82%\n",
      "\n",
      "\t Decision Tree: \n",
      "\t\tClassification accurary on the test data: 97.09%\n",
      "\n",
      "TEST RESULTS WITH SELECTED FEATURES:\n",
      "\t k-Nearest Neighbor: \n",
      "\t\tClassification accurary on the test data: 96.73%\n",
      "\n",
      "\t Gaussian Naive Bayes: \n",
      "\t\tClassification accurary on the test data: 91.64%\n",
      "\n",
      "\t Decision Tree: \n",
      "\t\tClassification accurary on the test data: 97.45%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing test results using all features vs using selected features\n",
    "\n",
    "print(\"TEST RESULTS WITH ALL FEATURES:\")\n",
    "# go through all estimators in dictionary \n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "        \n",
    "    #select a classifier\n",
    "    classifier = estimator_object\n",
    "        \n",
    "    #create the model by fitting the training data\n",
    "    classifier.fit(X=X_train, y=y_train)\n",
    "        \n",
    "    #make predictions on the test set\n",
    "    predicted = classifier.predict(X=X_test)\n",
    "        \n",
    "    #prediction accuracy\n",
    "    accuracy = classifier.score(X_test, y_test)\n",
    "        \n",
    "    print(\"\\t\", estimator_name + \": \\n\\t\\t\" + \"Classification accurary on the test data: \" + f\"{accuracy:.2%}\"+ \"\\n\")\n",
    "    \n",
    "\n",
    "print(\"TEST RESULTS WITH SELECTED FEATURES:\")\n",
    "# go through all estimators in dictionary \n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "        \n",
    "    #select a classifier\n",
    "    classifier = estimator_object\n",
    "        \n",
    "    #create the model by fitting the training data\n",
    "    classifier.fit(X=X_train_selected, y=y_train)\n",
    "        \n",
    "    #make predictions on the test set\n",
    "    predicted = classifier.predict(X=X_test_selected)\n",
    "        \n",
    "    #prediction accuracy\n",
    "    accuracy = classifier.score(X_test_selected, y_test)\n",
    "        \n",
    "    print(\"\\t\", estimator_name + \": \\n\\t\\t\" + \"Classification accurary on the test data: \" + f\"{accuracy:.2%}\"+ \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbor: \n",
      "\tmean accuracy=98.18%, standard deviation=1.35%\n",
      "\n",
      "Gaussian Naive Bayes: \n",
      "\tmean accuracy=90.43%, standard deviation=2.44%\n",
      "\n",
      "Decision Tree: \n",
      "\tmean accuracy=97.08%, standard deviation=1.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a metric that we are using is mean accuracy with standard deviation \n",
    "# we can see that on average, knn has the highest accuracy\n",
    "for estimator_name, estimator_object in estimators.items():\n",
    "    kfold = KFold(n_splits=10, random_state=3000, shuffle=True)\n",
    "    \n",
    "    scores = cross_val_score(estimator=estimator_object, X=features, y=target, cv=kfold)\n",
    "    \n",
    "    print(estimator_name + \": \\n\\t\" + f'mean accuracy={scores.mean():.2%}, ' \n",
    "          + f'standard deviation={scores.std():.2%}' +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   4   0]\n",
      " [  0 141   3]\n",
      " [  0   3 124]]\n"
     ]
    }
   ],
   "source": [
    "# another metric that we use is a confusion matrix\n",
    "# we know that correct predictions will be shown on the principal diagonal\n",
    "# nonzero values that are not on the principal diagonal indicate an incorrect prediction \n",
    "# each row represnts a distinct class (public, private, and for profit)\n",
    "# each column specifies how many test samples were classified into the 3 classes\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#create the model by fitting the training data\n",
    "knn.fit(X=X_train, y=y_train)\n",
    "\n",
    "#make predictions on the test set\n",
    "predicted = knn.predict(X=X_test)\n",
    "\n",
    "expected = y_test\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "\n",
    "confusion = confusion_matrix(y_true=expected, y_pred=predicted)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4. Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see from our results that knn and decision tree have the highest prediction accuracy so far\n",
    "# therefore will try to improve the performance even more by hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  KNeighborsClassifier(n_neighbors=3)\n",
      "Best parameters:  {'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "# these are the n_neighbors values that we want to test out\n",
    "param_grid1 = {\"n_neighbors\":[1, 2, 3, 4, 5, 10]}\n",
    "grid_search1 = GridSearchCV(KNeighborsClassifier(), param_grid1, cv=5)\n",
    "\n",
    "#fit the grid search object on the training data\n",
    "grid_search1.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "# result of grid search\n",
    "print(\"Best estimator: \", grid_search1.best_estimator_)\n",
    "print(\"Best parameters: \", grid_search1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:  DecisionTreeClassifier()\n",
      "Best parameters:  {'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# these are the max_depth values that we want to test out\n",
    "param_grid2 = {\"max_depth\":[1, None]}\n",
    "grid_search2 = GridSearchCV(DecisionTreeClassifier(), param_grid2, cv=5)\n",
    "\n",
    "#fit the grid search object on the training data\n",
    "grid_search2.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "# result of grid search\n",
    "print(\"Best estimator: \", grid_search2.best_estimator_)\n",
    "print(\"Best parameters: \", grid_search2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are hyperparameter tuning to find the best n_neighbors value and max_depth value\n",
    "# By doing this, we can optimize our algorithm's classification accuracy.\n",
    "# We also want our model to easily adapt to new sets of data so that it can \n",
    "# minimize the possibility of overfitting our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbor:: \n",
      "\tClassification accurary on the test data: 97.09%\n",
      "\n",
      "Decision Tree:: \n",
      "\tClassification accurary on the test data: 97.45%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after hyper parameter tuning, we will use those parameters because they will have the highest accuracy\n",
    "\n",
    "classifier1 = grid_search1.best_estimator_\n",
    "        \n",
    "#create the model by fitting the training data\n",
    "classifier1.fit(X=X_train_selected, y=y_train)\n",
    "        \n",
    "#make predictions on the test set\n",
    "predicted1 = classifier1.predict(X=X_test_selected)\n",
    "        \n",
    "#prediction accuracy\n",
    "accuracy1 = classifier1.score(X_test_selected, y_test)\n",
    "        \n",
    "print(\"k-Nearest Neighbor:\" + \": \\n\\t\" + \"Classification accurary on the test data: \" + f\"{accuracy1:.2%}\"+ \"\\n\")\n",
    "\n",
    "classifier2 = grid_search2.best_estimator_\n",
    "        \n",
    "#create the model by fitting the training data\n",
    "classifier2.fit(X=X_train_selected, y=y_train)\n",
    "        \n",
    "#make predictions on the test set\n",
    "predicted2 = classifier2.predict(X=X_test_selected)\n",
    "        \n",
    "#prediction accuracy\n",
    "accuracy2 = classifier2.score(X_test_selected, y_test)\n",
    "        \n",
    "print(\"Decision Tree:\" + \": \\n\\t\" + \"Classification accurary on the test data: \" + f\"{accuracy2:.2%}\"+ \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared k-Nearest Neighbors, Gaussian Naive Bayes, and Decision Tree. k-Nearest Neighbors and Decision Tree performed relatively the same, both performing better than Gaussian Naive Bayes. However, Decision Tree slightly outperformed k-Nearest Neighbors. After hyperparamter tuning, we found that an n_neighbors value of 3 and a the defualt max_depth value of None were optimal for our algorithms. Now, we were able to increase classficiation accuracy by about half of a percent. Therefore, we believe that Decision Tree should be used for our predictive model because it had the overall highest classification accuracy. \n",
    "\n",
    "We are able to predict our outcome variable of school type using our features such as enrollment count, in state tution cost, and out of state tuition cost. Using recursive feature elimination, we were able to conclude that in_state_tuition, out_of_state_total, and total_enrollment were the three most important features for our classification algorithm. When comparing our model using all the features vs the selected features, we found that our model performed better using only the selected features.\n",
    "\n",
    "An ethical implication our of project would be the issue of classism and how some are not able to afford an education. Those who are more affluent are often able to get into the schools they desire, while it may possbily be harder for someone not as wealthy to be able to get into and afford their dream school. \n",
    "\n",
    "If we were to do this project again, there are a few things that we would like to change. First, we would like to have more instances of for-profit schools. For-profit schools were severely under represented while public and private schools had many more instances in this dataset. Also, we could have had more feature columns such as international student count and also graduation rate. Intuitively, we think that public schools may possbily have a slightly lower graduation rate than a private school. We think this because private schools charge more tuition so one is less likely to drop out or else they would have lost more money. In the future, an extension of this project could use another classification algorithm such as Support Vector Machine and compare its performance to that of the algorithms we already trained and tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<hr style=\"height:2px; border:none; color:black; background-color:black;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTRIBUTIONS\n",
    "Sophia: Worked on Executive Summary, Introduction, Model Training\n",
    "\n",
    "Cheryl: Worked on Data Acquisition, Model Optimization, Dicussion\n",
    "\n",
    "Jacob: Worked on Data Analysis, Data Wrangling, Data Exploration, Model Testing\n",
    "\n",
    "Overall, we worked well as a group. Whenever we needed each other's support, we were able help each other. For the most part, we worked on all of the sections as a group and met in-person."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
